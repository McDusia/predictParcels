DEBUG:root:Reading data from database
DEBUG:root:Total samples in our dataset is: 219973
DEBUG:root:Total samples in our dataset is: 219973
INFO:root:Name: Nearest Neighbors
INFO:root:Score: 0.7961359245368792
INFO:root:Accuracy: 0.7961359245368792
INFO:root:Accuracy not normalised: 35026, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.560895853919769
INFO:root:              precision    recall  f1-score   support
           1       0.86      0.90      0.88     29243
           2       0.68      0.64      0.66     11601
           3       0.56      0.39      0.46      3151
    accuracy                           0.80     43995
   macro avg       0.70      0.64      0.66     43995
weighted avg       0.79      0.80      0.79     43995
INFO:root:Haming loss score: 0.2038640754631208
INFO:root:Name: Decision Tree
INFO:root:Score: 0.6718490737583817
INFO:root:Accuracy: 0.6718490737583817
INFO:root:Accuracy not normalised: 29558, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.04405631323827908
INFO:root:              precision    recall  f1-score   support
           1       0.67      1.00      0.80     29243
           2       0.60      0.03      0.05     11601
           3       0.62      0.05      0.09      3151
    accuracy                           0.67     43995
   macro avg       0.63      0.36      0.31     43995
weighted avg       0.65      0.67      0.55     43995
INFO:root:Haming loss score: 0.32815092624161835
INFO:root:Name: Random Forest
INFO:root:Score: 0.666030230708035
INFO:root:Accuracy: 0.666030230708035
INFO:root:Accuracy not normalised: 29302, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.0071552548615136935
INFO:root:              precision    recall  f1-score   support
           1       0.67      1.00      0.80     29243
           2       0.60      0.00      0.01     11601
           3       0.81      0.01      0.01      3151
    accuracy                           0.67     43995
   macro avg       0.69      0.34      0.27     43995
weighted avg       0.66      0.67      0.53     43995
INFO:root:Haming loss score: 0.333969769291965
INFO:root:Name: Neural Net
INFO:root:Score: 0.6646891692237754
INFO:root:Accuracy: 0.6646891692237754
INFO:root:Accuracy not normalised: 29243, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.0
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
INFO:root:              precision    recall  f1-score   support
           1       0.66      1.00      0.80     29243
           2       0.00      0.00      0.00     11601
           3       0.00      0.00      0.00      3151
    accuracy                           0.66     43995
   macro avg       0.22      0.33      0.27     43995
weighted avg       0.44      0.66      0.53     43995
INFO:root:Haming loss score: 0.3353108307762246
INFO:root:Name: AdaBoost
INFO:root:Score: 0.6751221729742016
INFO:root:Accuracy: 0.6751221729742016
INFO:root:Accuracy not normalised: 29702, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.07162229202557335
INFO:root:              precision    recall  f1-score   support
           1       0.68      0.99      0.81     29243
           2       0.52      0.05      0.09     11601
           3       0.59      0.06      0.10      3151
    accuracy                           0.68     43995
   macro avg       0.60      0.37      0.33     43995
weighted avg       0.63      0.68      0.57     43995
INFO:root:Haming loss score: 0.32487782702579837
INFO:root:Name: Naive Bayes
INFO:root:Score: 0.6612342311626321
INFO:root:Accuracy: 0.6612342311626321
INFO:root:Accuracy not normalised: 29091, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.005973191692629998
INFO:root:              precision    recall  f1-score   support
           1       0.67      0.99      0.80     29243
           2       0.25      0.01      0.02     11601
           3       0.40      0.02      0.03      3151
    accuracy                           0.66     43995
   macro avg       0.44      0.34      0.28     43995
weighted avg       0.54      0.66      0.54     43995
INFO:root:Haming loss score: 0.33876576883736786
INFO:root:Name: QDA
/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")
INFO:root:Score: 0.38302079781793386
INFO:root:Accuracy: 0.38302079781793386
INFO:root:Accuracy not normalised: 16851, Count of test set: 43995
INFO:root:Cohen Kappa score: 0.10898214283342689
INFO:root:              precision    recall  f1-score   support
           1       0.95      0.19      0.32     29243
           2       0.30      0.92      0.45     11601
           3       0.32      0.22      0.26      3151
    accuracy                           0.38     43995
   macro avg       0.52      0.44      0.34     43995
weighted avg       0.73      0.38      0.35     43995
INFO:root:Haming loss score: 0.6169792021820661
